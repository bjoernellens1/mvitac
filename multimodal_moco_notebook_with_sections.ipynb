{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "from utils import AverageMeter, accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from utils import accuracy, save_checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T15:39:25.404991281Z",
     "start_time": "2023-09-28T15:39:25.364163104Z"
    }
   },
   "id": "cbedf8ea2e0fa574"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from generate_dataset import TouchFolderLabel, CalandraLabel\n",
    "from model import MultiModalMoCo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T15:39:26.257452752Z",
     "start_time": "2023-09-28T15:39:26.251778756Z"
    }
   },
   "id": "2f66fd0ddfb717e8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e400b88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:39:27.914837623Z",
     "start_time": "2023-09-28T15:39:27.909172931Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ad424a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:39:52.380798241Z",
     "start_time": "2023-09-28T15:39:52.376997773Z"
    }
   },
   "outputs": [],
   "source": [
    "def logging(epoch, idx, train_loader_len, loss, acc1, acc5, losses, top1, top5, pretrain, train=True):\n",
    "    if pretrain:\n",
    "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "            'Loss {loss:.4f}'.format(\n",
    "            epoch, idx, train_loader_len, loss=loss))\n",
    "        wandb.log({\"training loss\": loss}, step=epoch * train_loader_len + idx)\n",
    "    else:\n",
    "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                epoch, idx, train_loader_len, loss=losses, top1=top1))\n",
    "        if train:\n",
    "            wandb.log({\"training loss\": loss,\n",
    "                        \"training accuracy\": acc1[0],\n",
    "                        \"training top5 accuracy\": acc5[0]}, \n",
    "                        step=epoch) \n",
    "        else:\n",
    "            wandb.log({\"validation loss\": loss,\n",
    "                        \"validation accuracy\": acc1[0],\n",
    "                        \"validation top5 accuracy\": acc5[0]}, \n",
    "                        step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "889d2453"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "log_every_n_epochs = 1\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "log_every_n_epochs = 50\n",
    "data_folder = \"/home/fotis/PycharmProjects/calandra_dataset/objects_split_object_wise/\"\n",
    "num_channels = 6\n",
    "momentum = 0.99\n",
    "temperature = 0.07\n",
    "lr = 0.0001\n",
    "weight_decay = 1e-6\n",
    "nn_model = 'resenet18'\n",
    "intra_dim = 128\n",
    "inter_dim = 128\n",
    "weight_inter_tv = 1\n",
    "weight_inter_vt = 1\n",
    "weight_intra_vision = 1\n",
    "weight_intra_tactile = 1\n",
    "pretrained_encoder = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T15:40:01.422199279Z",
     "start_time": "2023-09-28T15:40:01.420442547Z"
    }
   },
   "id": "82ecc33f1b9e9cd8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m dataset \u001B[38;5;241m=\u001B[39m ContrastiveLearningDataset(root_folder\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mget_dataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcalandra_label\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                                                   \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/mvitac/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:351\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[1;32m    350\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[0;32m--> 351\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    352\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    353\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/mvitac/venv/lib/python3.10/site-packages/torch/utils/data/sampler.py:107\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[0;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    104\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement))\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    108\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue, but got num_samples=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples))\n",
      "\u001B[0;31mValueError\u001B[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "from data_aug.contrastive_learning_dataset import ContrastiveLearningDataset\n",
    "\n",
    "dataset = ContrastiveLearningDataset(root_folder='data')\n",
    "train_dataset = dataset.get_dataset('calandra_label', 2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                                   num_workers=num_workers, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T15:40:02.222436176Z",
     "start_time": "2023-09-28T15:40:02.155851898Z"
    }
   },
   "id": "4dc9470762c4db43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load model\n",
    "model = MultiModalMoCo(n_channels=num_channels, m=momentum, T=temperature, nn_model=nn_model, intra_dim=intra_dim, inter_dim=inter_dim, weight_inter_t=weight_inter_tv, weight_inter_vt=weight_inter_vt, weight_intra_vision=weight_intra_vision, weight_intra_tactile=weight_intra_tactile, pretrained_encoder=pretrained_encoder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b18c80ebb8e04165"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with gpu: cuda.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining with gpu: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mparameters(), lr, weight_decay\u001B[38;5;241m=\u001B[39mweight_decay)\n\u001B[1;32m      5\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mCosineAnnealingLR(optimizer, T_max\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader), eta_min\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m      6\u001B[0m                                                        last_epoch\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      7\u001B[0m writer \u001B[38;5;241m=\u001B[39m SummaryWriter()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training with gpu: {device}.\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                       last_epoch=-1)\n",
    "writer = SummaryWriter()\n",
    "logging.basicConfig(filename=os.path.join(writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "# Set number of training epochs\n",
    "logging.info(f\"Start MViTaC training for {epochs} epochs.\")\n",
    "logging.info(f\"Training with gpu: {device}.\")\n",
    "best_acc = 0\n",
    "wandb.init(project=\"mvitac_pretrain\")\n",
    "for epoch in range(epochs):\n",
    "    loss_epoch = 0\n",
    "    pbar = tqdm(total=len(train_loader))\n",
    "    for idx, values in pbar:\n",
    "        x_vision_q, x_vision_k, x_tactile_q, x_tactile_k, label = values\n",
    "        model.train()\n",
    "        \n",
    "        # send to device\n",
    "        x_vision_q = x_vision_q.to(device)\n",
    "        x_vision_k = x_vision_k.to(device)\n",
    "\n",
    "        x_tactile_q = x_tactile_q.to(device)\n",
    "        x_tactile_k = x_tactile_k.to(device)\n",
    "\n",
    "        # Forward pass to get the loss\n",
    "        loss, logits, labels = model(x_vision_q, x_vision_k, x_tactile_q, x_tactile_k, epoch, idx, len(train_loader))\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = loss_epoch / len(train_loader)\n",
    "    if epoch % log_every_n_epochs == 0:\n",
    "        top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "        writer.add_scalar('loss', avg_loss, global_step=epoch)\n",
    "        writer.add_scalar('acc/top1', top1[0], global_step=epoch)\n",
    "        writer.add_scalar('acc/top5', top5[0], global_step=epoch)\n",
    "        writer.add_scalar('learning_rate', scheduler.get_last_lr()[0], global_step=epoch)\n",
    "        if top1[0] > best_acc:\n",
    "            best_acc = top1[0]\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'arch': 'resnet18',\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, is_best=True, filename=os.path.join(writer.log_dir, f'checkpoint_best.pth.tar'))\n",
    "        # torch.save(state, f'models/calandra/model_{args.task}_{epoch}_{args.batch_size}_best_object_wise_05_t05.pth')\n",
    "        wandb.save('models/calandra/model_{}_best_object_wise.pth'.format(epoch))\n",
    "        \n",
    "    # warmup for the first 10 epochs\n",
    "    if epoch >= 10:\n",
    "        scheduler.step()\n",
    "    logging.debug(f\"Epoch: {epoch}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "\n",
    "    logging.info(\"Training has finished.\")\n",
    "    # save model checkpoints\n",
    "    checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(epochs)\n",
    "    save_checkpoint({\n",
    "        'epoch': epochs,\n",
    "        'arch': 'resnet18',\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best=False, filename=os.path.join(writer.log_dir, checkpoint_name))\n",
    "    logging.info(f\"Model checkpoint and metadata has been saved at {writer.log_dir}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T15:39:47.368606662Z",
     "start_time": "2023-09-28T15:39:45.355499417Z"
    }
   },
   "id": "65a426de0c22ced2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fe5b5d5b439fa08e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
